{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import KeyedVectors, Word2Vec, phrases\n",
    "from gensim.parsing import preprocessing\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation,strip_numeric,remove_stopwords\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import LdaModel\n",
    "from os import walk\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Clean data\n",
    "def text_cleaning(data):\n",
    "    new_sentences = []\n",
    "    filters = [lambda x: x.lower(), strip_tags, strip_punctuation,strip_numeric,remove_stopwords]\n",
    "    excluded = ['breast', 'cancer', 'survivorship', 'born', 'alive', 'live', 'die', 'died']\n",
    "    for i in range(data.shape[0]):\n",
    "        txt = data.iloc[i]\n",
    "        txt = txt.lower()\n",
    "        txt = re.sub(\"(#.*?)[\\s]\",\" \",txt) # remove all # from tweets\n",
    "        txt = re.sub(\"breastcancer\",\" \",txt)\n",
    "        \n",
    "        c_words = []\n",
    "        words = preprocessing.preprocess_string(txt, filters)\n",
    "        for w in words:\n",
    "            if len(w)>3 and w not in excluded:\n",
    "                c_words.append(w)\n",
    "\n",
    "        new_sentences.append(c_words)\n",
    "    \n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my mom could have worked while dying from stage 4 breast cancer & paid for tx out of pocket?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original data\n",
    "data = pd.read_csv(\"breast_cancer.csv\")['Text']\n",
    "sentences_bcancer = text_cleaning(data)\n",
    "original_bcancer = data.to_numpy()\n",
    "original_bcancer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create best Bigrams of tweets(calculated based on how often words come together in all tweets)\n",
    "bigram = gensim.models.Phrases(sentences_bcancer) \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "sentences_bcancer = [bigram_mod[doc] for doc in sentences_bcancer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chemotherapy',\n",
       " 'chemo',\n",
       " 'radiotherapy',\n",
       " 'evista',\n",
       " 'raloxifene',\n",
       " 'hydrochloride',\n",
       " 'raloxifene_hydrochloride',\n",
       " 'tamoxifen',\n",
       " 'citrate',\n",
       " 'tamoxifen_citrate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original lexicon\n",
    "data_lexicon = pd.read_csv(\"brest_cancer_lexicon.csv\")['Drug'].to_numpy()\n",
    "data_lexicox_clean = [\"_\".join(data.lower().split()) for data in data_lexicon]\n",
    "data_lexicox_clean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from drug-related w2vec\n",
    "path_tune = \"/Users/thiago/Github/Data/BioW2Vec/DSM-language-model-1B-LARGE/trig-vectors-phrase.bin\"\n",
    "word_vectors = KeyedVectors.load_word2vec_format(path_tune, binary=True, encoding='utf8', unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chemotherapy', 'chemo', 'bleomycin', 'chemo_radiation', 'cisplatin', 'lymphoma', 'chemo', 'chemotherapy', 'chemo_treatments', 'chemo_radiation']\n"
     ]
    }
   ],
   "source": [
    "# expand original lexion, if not done yet\n",
    "expand = False\n",
    "expanded = []\n",
    "if expand:\n",
    "    for word in data_lexicox_clean:\n",
    "        if word in word_vectors:\n",
    "            expanded.append(word)\n",
    "            similar = [x[0] for x in word_vectors.most_similar(word,topn=5)]\n",
    "            expanded.extend(similar)\n",
    "    \n",
    "    # save to file\n",
    "    out = \"brest_cancer_lexicon_expanded.csv\"\n",
    "    dict = {'Drug': expanded}   \n",
    "       \n",
    "    df = pd.DataFrame(dict) \n",
    "    # saving the dataframe  \n",
    "    df.to_csv(out)  \n",
    "    print(expanded[0:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load expanded lexicon\n",
    "data_lexicon_expanded = pd.read_csv(\"brest_cancer_lexicon_expanded.csv\")['Drug'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on a giving tweet word from user, database of lexicon and ratio\n",
    "# return a list of all words from user which is misspelled and are breast cancer expression\n",
    "import Levenshtein\n",
    "def get_mispelling( w_tweet, database, ratio):\n",
    "    out = []\n",
    "    for treatment in database:\n",
    "        lev_ratio = Levenshtein.ratio(treatment,w_tweet)\n",
    "        if lev_ratio > ratio:\n",
    "            out.append(treatment)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each tweet, let's find if tweet has a treatment\n",
    "#original_bcancer\n",
    "new_database = []\n",
    "treatment = []\n",
    "for index,tweet in enumerate(sentences_bcancer):\n",
    "    for word in tweet:\n",
    "        if word in data_lexicon_expanded:\n",
    "            new_database.append(original_bcancer[index])\n",
    "            treatment.append(word)\n",
    "        else:\n",
    "            mispelled = get_mispelling(word,data_lexicon_expanded, 0.75)\n",
    "            if len(mispelled) >0:\n",
    "                for term in mispelled: # add tweet multiple times if have more than 1 treatment\n",
    "                    new_database.append(original_bcancer[index])\n",
    "                    treatment.append(term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Before we start our Advent Calendar, we have a...</td>\n",
       "      <td>stearate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jo has had a tough 24 hours, poor nights sleep...</td>\n",
       "      <td>chemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Current state. Stucco remediation thanks to @t...</td>\n",
       "      <td>stearate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"$mrk \\n\\nwhispers we hear is keytruda slated...</td>\n",
       "      <td>keytruda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b\"$mrk \\n\\nwhispers we hear is keytruda slated...</td>\n",
       "      <td>sulfate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>b\"#iamasurvivor and i will push for progress b...</td>\n",
       "      <td>herceptin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>b\"@senamyklobuchar @sentinasmith why haven't e...</td>\n",
       "      <td>halaven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>b'@joebiden no it's gone &amp;amp; thank god. it s...</td>\n",
       "      <td>stearate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>b'@dailymailceleb @dailymailuk lovely see @kyl...</td>\n",
       "      <td>regimins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>b'@drkcain as a breast cancer patient myself f...</td>\n",
       "      <td>albumin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1498 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Treatment\n",
       "0     Before we start our Advent Calendar, we have a...   stearate\n",
       "1     Jo has had a tough 24 hours, poor nights sleep...      chemo\n",
       "2     Current state. Stucco remediation thanks to @t...   stearate\n",
       "3     b\"$mrk \\n\\nwhispers we hear is keytruda slated...   keytruda\n",
       "4     b\"$mrk \\n\\nwhispers we hear is keytruda slated...    sulfate\n",
       "...                                                 ...        ...\n",
       "1493  b\"#iamasurvivor and i will push for progress b...  herceptin\n",
       "1494  b\"@senamyklobuchar @sentinasmith why haven't e...    halaven\n",
       "1495  b'@joebiden no it's gone &amp; thank god. it s...   stearate\n",
       "1496  b'@dailymailceleb @dailymailuk lovely see @kyl...   regimins\n",
       "1497  b'@drkcain as a breast cancer patient myself f...    albumin\n",
       "\n",
       "[1498 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save new dataset\n",
    "out = \"brest_cancer_by_treatments.csv\"\n",
    "dict = {'Tweet': new_database, \"Treatment\":treatment }   \n",
    "\n",
    "df = pd.DataFrame(dict) \n",
    "# saving the dataframe  \n",
    "df.to_csv(out)  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
